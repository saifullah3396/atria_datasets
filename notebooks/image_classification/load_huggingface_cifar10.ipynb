{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Dataset Handling with Atria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Auto-reloading Modules\n",
    "We enable auto-reloading of modules so that any changes in imported libraries are automatically reflected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies\n",
    "Here, we modify the system path to include the project's root directory and import necessary modules for dataset handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the CIFAR-10 Dataset\n",
    "We load the CIFAR-10 dataset using the `CIFAR10.load` method, specifying the training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-28 03:22:18][atria.data.datasets.atria_dataset][INFO] Loading dataset HuggingfaceCifar10/plain_text from registry.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-28 03:22:20][atria.data.datasets.atria_dataset][INFO] Setting up dataset type with split=train\n",
      "[2025-04-28 03:22:20][atria.data.datasets.atria_dataset][INFO] No storage manager provided. Preparing downloads and split iterator.\n",
      "Downloading data: 100%|██████████| 120M/120M [00:11<00:00, 10.5MB/s] \n",
      "Downloading data: 100%|██████████| 23.9M/23.9M [00:02<00:00, 10.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "from atria_core.types import DatasetSplit\n",
    "from atria_core.types import ImageInstance\n",
    "from atria_examples.datasets.cifar10_huggingface import HuggingfaceCifar10\n",
    "\n",
    "cifar10 = HuggingfaceCifar10.load(\n",
    "    split=DatasetSplit.train,\n",
    "    config_name='plain_text',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageInstance(\n",
       "    index=0,\n",
       "    id=UUID('73c861b9-3b9a-456a-bbbc-13e3dfa25130'),\n",
       "    image=Image(\n",
       "        file_path=None,\n",
       "        content=<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x79EFA8FFB7A0>,\n",
       "        source_size=None,\n",
       "        shape=(3, 32, 32),\n",
       "        dtype=None\n",
       "    ),\n",
       "    label=Label(value=0, name='airplane')\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract a sample instance from the dataset\n",
    "next(iter(cifar10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating batched instances from a list of samples\n",
    "We create a list of samples and then call batched on the list which is the class method of the specific instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageInstance(\n",
       "    batch_size=2,\n",
       "    index=[0, 1],\n",
       "    id=[\n",
       "        UUID('920b3bed-92e2-4e43-afb3-749fae4aefc9'),\n",
       "        UUID('69349f28-b889-4a54-84b2-575c0911a143')\n",
       "    ],\n",
       "    image=Image(\n",
       "        batch_size=2,\n",
       "        file_path=None,\n",
       "        content=tensor([[[[0.6980, 0.6980, 0.6980,  ..., 0.6667, 0.6588, 0.6471],\n",
       "          [0.7059, 0.7020, 0.7059,  ..., 0.6784, 0.6706, 0.6588],\n",
       "          [0.6941, 0.6941, 0.6980,  ..., 0.6706, 0.6627, 0.6549],\n",
       "          ...,\n",
       "          [0.4392, 0.4431, 0.4471,  ..., 0.3922, 0.3843, 0.3961],\n",
       "          [0.4392, 0.4392, 0.4431,  ..., 0.4000, 0.4000, 0.4000],\n",
       "          [0.4039, 0.3922, 0.4039,  ..., 0.3608, 0.3647, 0.3569]],\n",
       "\n",
       "         [[0.6902, 0.6902, 0.6902,  ..., 0.6588, 0.6510, 0.6392],\n",
       "          [0.6980, 0.6941, 0.6980,  ..., 0.6706, 0.6627, 0.6510],\n",
       "          [0.6863, 0.6863, 0.6902,  ..., 0.6627, 0.6549, 0.6471],\n",
       "          ...,\n",
       "          [0.4196, 0.4275, 0.4314,  ..., 0.3804, 0.3686, 0.3725],\n",
       "          [0.4000, 0.4039, 0.4039,  ..., 0.3725, 0.3647, 0.3608],\n",
       "          [0.3765, 0.3647, 0.3725,  ..., 0.3294, 0.3373, 0.3294]],\n",
       "\n",
       "         [[0.7412, 0.7412, 0.7412,  ..., 0.7059, 0.6941, 0.6824],\n",
       "          [0.7490, 0.7451, 0.7490,  ..., 0.7137, 0.7059, 0.6941],\n",
       "          [0.7373, 0.7373, 0.7412,  ..., 0.7059, 0.6980, 0.6902],\n",
       "          ...,\n",
       "          [0.4196, 0.4235, 0.4314,  ..., 0.3686, 0.3647, 0.3725],\n",
       "          [0.3961, 0.4000, 0.4039,  ..., 0.3647, 0.3569, 0.3569],\n",
       "          [0.3608, 0.3529, 0.3686,  ..., 0.3137, 0.3137, 0.3020]]],\n",
       "\n",
       "\n",
       "        [[[0.1137, 0.0863, 0.0980,  ..., 0.7725, 0.7765, 0.7804],\n",
       "          [0.1216, 0.1059, 0.0667,  ..., 0.8235, 0.8196, 0.8196],\n",
       "          [0.1569, 0.1216, 0.0784,  ..., 0.8235, 0.8235, 0.8235],\n",
       "          ...,\n",
       "          [0.1765, 0.0941, 0.0627,  ..., 0.0980, 0.0941, 0.0941],\n",
       "          [0.0824, 0.0706, 0.1059,  ..., 0.1020, 0.1137, 0.1098],\n",
       "          [0.2078, 0.3176, 0.3804,  ..., 0.0863, 0.0941, 0.0902]],\n",
       "\n",
       "         [[0.1686, 0.1412, 0.1451,  ..., 0.8588, 0.8588, 0.8706],\n",
       "          [0.1804, 0.1608, 0.1137,  ..., 0.9098, 0.9059, 0.9059],\n",
       "          [0.2157, 0.1765, 0.1294,  ..., 0.9098, 0.9098, 0.9098],\n",
       "          ...,\n",
       "          [0.1490, 0.0824, 0.0549,  ..., 0.1137, 0.1098, 0.1098],\n",
       "          [0.0706, 0.0510, 0.0627,  ..., 0.1176, 0.1294, 0.1255],\n",
       "          [0.1569, 0.2431, 0.2745,  ..., 0.1020, 0.1098, 0.1059]],\n",
       "\n",
       "         [[0.0392, 0.0157, 0.0627,  ..., 0.5373, 0.5373, 0.5490],\n",
       "          [0.0353, 0.0235, 0.0235,  ..., 0.5804, 0.5804, 0.5804],\n",
       "          [0.0627, 0.0314, 0.0275,  ..., 0.5882, 0.5843, 0.5843],\n",
       "          ...,\n",
       "          [0.0902, 0.0431, 0.0275,  ..., 0.1255, 0.1216, 0.1216],\n",
       "          [0.0275, 0.0118, 0.0196,  ..., 0.1294, 0.1412, 0.1373],\n",
       "          [0.0902, 0.1490, 0.1686,  ..., 0.1137, 0.1216, 0.1176]]]]),\n",
       "        source_size=None,\n",
       "        shape=torch.Size([2, 3, 32, 32]),\n",
       "        dtype=torch.float32\n",
       "    ),\n",
       "    label=Label(\n",
       "        batch_size=2,\n",
       "        value=tensor([0, 6]),\n",
       "        name=['airplane', 'frog']\n",
       "    )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a list of instances\n",
    "instances = []\n",
    "for idx, sample in enumerate(cifar10):\n",
    "    instances.append(sample.to_tensor())\n",
    "    if (idx + 1) >= 2:\n",
    "        break\n",
    "\n",
    "# Batch the instances\n",
    "instances[0].batched(instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset handling with File Storage\n",
    "Load the dataset with a file storage manager that first caches the data into disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atria.data.storage.file_storage_manager import FileStorageManager\n",
    "from atria.data.storage.utilities import FileStorageType\n",
    "\n",
    "# Creat a file storage manager\n",
    "file_storage_manager = FileStorageManager(\n",
    "    storage_dir=\"/tmp\", streaming_mode=False, storage_type=FileStorageType.MSGPACK, \n",
    "    max_samples=100, # save up to 100 samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-28 03:23:35][atria.data.datasets.atria_dataset][INFO] Loading dataset HuggingfaceCifar10/plain_text from registry.\n",
      "[2025-04-28 03:23:37][atria.data.datasets.atria_dataset][INFO] Setting up dataset type with split=train\n",
      "[2025-04-28 03:23:37][atria.data.storage.file_storage_manager][INFO] Preparing dataset split train to cache dir /tmp/msgpack/HuggingfaceCifar10/plain_text/a061c9f2b33df971/max_samples-100 with max samples 100.\n",
      "2025-04-28 03:23:38,069\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Writing dataset HuggingfaceCifar10 to FileStorageType.MSGPACK: 0it [00:00, ?it/s]2025-04-28 03:23:39,105\tINFO worker.py:1816 -- Started a local Ray instance.\n",
      ":job_id:01000000\n",
      ":actor_name:FileStorageShardWriterActor\n",
      "[2025-04-28 03:23:39][atria.data.storage.msgpack_shard_writer][INFO] # Writing /tmp/msgpack/HuggingfaceCifar10/plain_text/a061c9f2b33df971/max_samples-100/train-000000-000000.msgpack, 0 samples, 0.0 GB, 0 total samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":job_id:01000000\n",
      ":actor_name:FileStorageShardWriterActor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing dataset HuggingfaceCifar10 to FileStorageType.MSGPACK: 99it [00:01, 62.56it/s]\n",
      "train-000000-000000.msgpack   0% 00:00<?, ?it/s\n",
      "[2025-04-28 03:23:39][atria.data.datasets.metadata][INFO] Writing dataset storage info to /tmp/msgpack/HuggingfaceCifar10/plain_text/a061c9f2b33df971/max_samples-100/train_storage_info.json:\n",
      "AtriaDatasetStorageInfo(\n",
      "    metadata=DatasetMetadata(\n",
      "        dataset_name='HuggingfaceCifar10',\n",
      "        citation='',\n",
      "        homepage='',\n",
      "        license='',\n",
      "        config=AtriaHuggingfaceDatasetConfig(\n",
      "            name='plain_text',\n",
      "            description=None,\n",
      "            version='0.0.0',\n",
      "            data_urls=None,\n",
      "            hf_repo='uoft-cs/cifar10'\n",
      "        ),\n",
      "        dataset_labels=DatasetLabels(\n",
      "            instance_classification=[\n",
      "                'airplane',\n",
      "                'automobile',\n",
      "                'bird',\n",
      "                'cat',\n",
      "                'deer',\n",
      "                'dog',\n",
      "                'frog',\n",
      "                'horse',\n",
      "                'ship',\n",
      "                'truck'\n",
      "            ],\n",
      "            object_classification=None,\n",
      "            token_classification=None\n",
      "        ),\n",
      "        data_model=<class 'atria_core.types.ImageInstance'>\n",
      "    ),\n",
      "    split_info=SplitInfo(\n",
      "        num_bytes=5050,\n",
      "        num_examples=100,\n",
      "        shards=[\n",
      "            DatasetShardInfo(\n",
      "                url='/tmp/msgpack/HuggingfaceCifar10/plain_text/a061c9f2b33df971/max_samples-100/train-000000-000000.msgpack',\n",
      "                shard=1,\n",
      "                total=100,\n",
      "                count=100,\n",
      "                size=5050\n",
      "            )\n",
      "        ]\n",
      "    )\n",
      ").\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 samples written\n"
     ]
    }
   ],
   "source": [
    "from atria_core.types import DatasetSplit\n",
    "from atria_examples.datasets.cifar10_huggingface import HuggingfaceCifar10\n",
    "\n",
    "# load the dataset with the file storage manager\n",
    "cifar10 = HuggingfaceCifar10.load(\n",
    "    split=DatasetSplit.train,\n",
    "    storage_manager=file_storage_manager,\n",
    "    config_name='plain_text',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageInstance(\n",
      "    index=0,\n",
      "    id=UUID('64ba361d-dca7-4b8c-9f75-f61eb661dfd3'),\n",
      "    image=Image(\n",
      "        file_path=None,\n",
      "        content=<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x79EFA8ED8110>,\n",
      "        source_size=None,\n",
      "        shape=(3, 32, 32),\n",
      "        dtype=None\n",
      "    ),\n",
      "    label=Label(value=0, name='airplane')\n",
      ")\n",
      "ImageInstance(\n",
      "    index=0,\n",
      "    id=UUID('64ba361d-dca7-4b8c-9f75-f61eb661dfd3'),\n",
      "    image=Image(\n",
      "        file_path=None,\n",
      "        content=<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x79EFD9B3E900>,\n",
      "        source_size=None,\n",
      "        shape=(3, 32, 32),\n",
      "        dtype=None\n",
      "    ),\n",
      "    label=Label(value=0, name='airplane')\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Extract a sample instance from the dataset\n",
    "print(cifar10[0])\n",
    "print(next(iter(cifar10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atriax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
